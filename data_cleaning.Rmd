---
title: "Rallying for Change: The Effect of Protests on Political Fundraising in the U.S. (Data Cleaning)"
author: "Nick Pangakis and Dan Gillion"
output: 
  pdf_document:
    number_sections: yes
    toc: yes
    toc_depth: '4'
  html_document:
    code_folding: show
    highlight: haddock
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 4
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
urlcolor: blue
editor_options: 
  chunk_output_type: inline
---

\pagebreak

# Overview - Data Preparation

How do protests influence American political behavior? This project investigates how political protests affect an individual's willingness to donate money to a federal political campaign. In this markdown, I describe the data cleaning procedures associated with this project. 

This study merges data from two sources:

1.  First, we harness a dataset on the timing and location of social protests occurring across the United States (2017-2022) from a nonpartisan nonprofit called [Crowd Counting Consortium (CCC)](https://sites.google.com/view/crowdcountingconsortium/home?authuser=0). The CCC collects publicly available data on political crowds reported in the United States, including marches, protests, strikes, demonstrations, riots, and other actions. The data is available for public download.

2.  Second, we access all individual-level campaign contributions to federal elections (2017-2022). This data comes from the [Federal Election Commission](https://www.fec.gov/data/browse-data/?tab=bulk-data), which is available for public download.

\pagebreak

```{r setup}
knitr::opts_chunk$set(echo = TRUE, fig.width=8, fig.height=4, include=TRUE, eval=FALSE)
options(scipen = 0, digits = 3)  # controls base R output
if(!require('pacman')) {
  install.packages('pacman')
}
pacman::p_load(tidyverse, RCurl, here, 
               data.table, bit64, stringr, 
               readxl, tidyr, gender, wru) 
```

# Protest Data (2017-2022)

In this first section, we download the protest data from the CCC and clean/shape the protest data. The raw data contains the location and timing of political protests occurring across the country from 2017 to 2022. We aggregate the protest data by day, county, and year. As a result, the data include the number of protests occurring in a county in a given day for each year from 2017 to 2022.

We include numerous operationalizations of protest activity. These include restricting the dataset to only larger protest events, only liberal protests, and only conservative protests.

### Load in data

```{r Download raw data and clean data}
# Load in protest data
protest_raw <-
  read.csv(text = getURL(
      "https://raw.githubusercontent.com/nonviolent-action-lab/crowd-counting-consortium/master/ccc_compiled.csv"))

# Data Wrangling - see data dictionary (https://github.com/nonviolent-action-lab/crowd-counting-consortium/blob/master/ccc_data_dictionary.md)
protest_clean_all <- protest_raw %>%
  filter(online == 0) %>%  # Binary indicator for online-only events. 1 = yes, 0 = no.)
  select(
    date, # Date of event in YYYY-MM-DD format (character)
    state, # Two-letter U.S. postal abbreviation for the state
    type, # Type(s) of action (e.g. march, protest, demonstration, strike, counter-protest, sit-in), separated with semi-colons if more than one.
    valence, # Political valence of the event relative to President Trump, broadly construed. 2 = pro-Trump, 1 = anti-Trump, 0 = neither or unrelated. 
    issues, # String of semicolon-separated tags identifying political issues associated with the event (e.g., "democracy; women's rights" for events associated with the 2017 Women's March)
    size_mean, # Average of size_low and size_high (which in most cases is the same value).
    fips_code # Five-digit FIPS code for the county
  ) %>%
  # limit to only US states
  filter(state != "VI" & state != "GU" & state != "PR") %>% 
  # cast data types and clean some variables
  mutate(fips_code = as.character(fips_code),
      fips_code = case_when(nchar(fips_code) == 4 ~ paste0("0", fips_code),TRUE ~ fips_code),
      year = str_split_fixed(date,"-",2)[,1],
      # recode valence to factor
      valence = as.factor(recode(valence,
      "2" = "conservative",
      "1" = "liberal",
      "0" = "independent"
    )),
  ) %>% 
  # filter for subset of years
  filter(year == 2017 | year == 2018 | year == 2019 | year == 2020 | year == 2021 | year == 2022)

# load to get full list of counties and zip codes --- to ensure that every county is represented
zip_to_county_data <- read_excel("ZIP_COUNTY_092021.xlsx") %>% 
  select(1, 2) %>% 
  # limit to unique zip codes (bc several zip codes lie in multiple counties)
  distinct_at(vars(ZIP), .keep_all = T)

```

### Helper Functions

```{r Create function for subsetting and aggregating protest data}
# Create function to aggregate number of daily protests in a county
protest_wrangling <- function(data, size){
  ### Size argument refers to whether protests are aggregated by number of protest attendees or protest events
  if (size == 1){
    ##### Aggregate daily protests in a county by number of protest attendees
      data_new <- data %>% 
        # group by fips county code and day
        group_by(fips_code, date) %>%
        # count number of people attending protests per day per county (main operationalization of protests)
        summarize(protests = sum(size_mean)) %>%
        # join with the county data by county
        right_join(unique(zip_to_county_data["COUNTY"]), by= c("fips_code"="COUNTY")) %>%
        ungroup() %>%
        # create every combination of day and fips county
        tidyr::complete(date, fips_code) %>%
        # fill NA values with 0 (since not every county has protests in a given day)
        replace_na(list(n=0)) %>%
        # drop any remaining NAs
        drop_na()
  } else {
    ##### Aggregate daily protests in a county by number of protest events
    data_new <- data %>% 
      # group by fips county code and day
      group_by(fips_code, date) %>%
      # count protests per day per county
      count() %>%
      # join with the county data by county
      right_join(unique(zip_to_county_data["COUNTY"]), by= c("fips_code"="COUNTY")) %>%
      ungroup() %>%
      # create every combination of day and fips county
      tidyr::complete(date, fips_code) %>%
      # fill NA values with 0 (since not every county has protests in a given day)
      replace_na(list(n=0)) %>%
      # drop any remaining NAs
      drop_na() 
  }
  return(data_new)
}

### Dealing with missing values
# Since not every date has a donation in every county, not every date-county pair populates. 
# Manually add in missing date-county pairs
full_dates <- seq.Date(as.IDate("2017-01-01"), as.IDate("2022-12-31"), by="days")
full_counties <- unique(zip_to_county_data$COUNTY)
county_date_pairs <- expand.grid(full_dates, full_counties) %>% 
  rename(date = Var1, fips_code = Var2) %>% 
  mutate(date = as.character(date))

```

```{r Subset and aggregate the protest data -- size of protests daily}

# Aggregate total protestsby number of people attending per county per day

# Subset = sum of all 'protest' attendees
# used as primary data
protest_size_all <- protest_clean_all %>% 
  filter(!is.na(size_mean)) %>% 
  protest_wrangling(size=1)  %>% 
  rename(protests_size_all = protests)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_size_all[,c("date","fips_code")]) %>% 
  mutate(protests_size_all = 0)
protest_size_all <- rbind(protest_size_all, missing)

# Subset = sum of all 'protest' attendees at liberal protests
protest_size_lib <- protest_clean_all %>% 
  filter(valence == "liberal",!is.na(size_mean)) %>% 
  protest_wrangling(size=1)  %>% 
  rename(protests_size_liberal = protests)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_size_lib[,c("date","fips_code")]) %>% 
  mutate(protests_size_liberal = 0)
protest_size_lib <- rbind(protest_size_lib, missing)

# Subset = sum of all 'protest' attendees at conservative protests
protest_size_con <- protest_clean_all %>% 
    filter(valence == "conservative", !is.na(size_mean)) %>% 
    protest_wrangling(size=1) %>% 
    rename(protests_size_conservative = protests)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_size_con[,c("date","fips_code")]) %>% 
  mutate(protests_size_conservative = 0)
protest_size_con <- rbind(protest_size_con, missing)

# Subset = sum of all 'protest' attendees at racial protests
protest_size_rac <- protest_clean_all %>% 
    filter(!is.na(size_mean), str_detect(issues, "racism") | str_detect(issues, "policing") |
               str_detect(issues, "criminal justice")) %>% 
    protest_wrangling(size=1) %>% 
    rename(protests_size_racial = protests) 
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_size_rac[,c("date","fips_code")]) %>% 
  mutate(protests_size_racial = 0)
protest_size_rac <- rbind(protest_size_rac, missing)

# Subset = sum of all 'protest' attendees at womens protests
protest_size_wo <- protest_clean_all %>% 
    filter(!is.na(size_mean),
           str_detect(issues, "women's rights") | str_detect(issues, "reproductive rights") |
               str_detect(issues, "sexual violence")) %>% 
    protest_wrangling(size=1) %>% 
    rename(protests_size_women = protests)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_size_wo[,c("date","fips_code")]) %>% 
  mutate(protests_size_women = 0)
protest_size_wo <- rbind(protest_size_wo, missing)

########## Supplemental data

# Exclude rallies - limit to protests, walkout, march, demonstration, vigil, strike, gathering, sit-in, picket 
protest_size_noral <- protest_clean_all %>%
    mutate(type = tolower(type)) %>%
    filter(!is.na(size_mean), str_detect(type,
                      "protest|walkout|march|demonstration|vigil|strike|gathering|sit|picket")) %>%
    protest_wrangling(size=1) %>% 
    rename(protests_size_norallies = protests) 
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_size_noral[,c("date","fips_code")]) %>% 
  mutate(protests_size_norallies = 0)
protest_size_noral <- rbind(protest_size_noral, missing)

# Combine protest by day data into a dataframe
protest_size <- protest_size_all %>% 
  inner_join(protest_size_lib, by = c("date", "fips_code")) %>% 
  inner_join(protest_size_con, by = c("date", "fips_code")) %>%
  inner_join(protest_size_rac, by = c("date", "fips_code")) %>%
  inner_join(protest_size_wo, by = c("date", "fips_code")) %>% 
  inner_join(protest_size_noral, by = c("date", "fips_code"))
```

```{r Subset and aggregate the protest data -- number of protests daily}

# Aggregate total protests per county per day

# Subset = 'protest' events with over 30 people
protest_daily_large <- protest_clean_all %>% 
  filter(size_mean > 30) %>% 
  protest_wrangling(size=0)  %>% 
  rename(protests_large = n)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_daily_large[,c("date","fips_code")]) %>% 
  mutate(protests_large = 0)
protest_daily_large <- rbind(protest_daily_large, missing)

# Subset = Liberal protest (only protests over 30 people)
protest_daily_liberal <- protest_clean_all %>% 
  filter(size_mean > 30) %>% 
  filter(valence == "liberal") %>% 
  protest_wrangling(size=0)  %>% 
  rename(protests_liberal = n)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_daily_liberal[,c("date","fips_code")]) %>% 
  mutate(protests_liberal = 0)
protest_daily_liberal <- rbind(protest_daily_liberal, missing)

# Subset = conservative protest (only protests over 30 people)
protest_daily_conservative <- protest_clean_all %>% 
    filter(size_mean>30) %>%
    filter(valence == "conservative") %>% 
    protest_wrangling(size=0) %>% 
    rename(protests_conservative = n)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_daily_conservative[,c("date","fips_code")]) %>% 
  mutate(protests_conservative = 0)
protest_daily_conservative <- rbind(protest_daily_conservative, missing)

# Subset = racial protests (only protests over 30 people)
protest_daily_racial <- protest_clean_all %>% 
    filter(size_mean>30) %>%
    filter(str_detect(issues, "racism") | str_detect(issues, "policing") |
               str_detect(issues, "criminal justice")) %>% 
    protest_wrangling(size=0) %>% 
    rename(protests_racial = n) 
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_daily_racial[,c("date","fips_code")]) %>% 
  mutate(protests_racial = 0)
protest_daily_racial <- rbind(protest_daily_racial, missing)

# Subset = women's rights protests (only protests over 30 people)
protest_daily_women <- protest_clean_all %>% 
    filter(size_mean>30) %>%
    filter(str_detect(issues, "women's rights") | str_detect(issues, "reproductive rights") |
               str_detect(issues, "sexual violence")) %>% 
    protest_wrangling(size=0) %>% 
    rename(protests_women = n)
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_daily_women[,c("date","fips_code")]) %>% 
  mutate(protests_women = 0)
protest_daily_women <- rbind(protest_daily_women, missing)

########## Supplemental data

# full data
protest_daily_all <- protest_clean_all %>% 
    protest_wrangling(size=0) %>% 
    rename(protests_all = n)
# no missing counties

# Exclude rallies - limit to protests, walkout, march, demonstration, vigil, strike, gathering, sit-in, picket  (only protests over 30 people)
protest_daily_norallies <- protest_clean_all %>%
    mutate(type = tolower(type)) %>%
    filter(size_mean > 30,
           str_detect(type,
                      "protest|walkout|march|demonstration|vigil|strike|gathering|sit|picket")) %>%
    protest_wrangling(size=0) %>% 
    rename(protests_norallies = n) 
# Find and replace missing date-county pairs
missing <- anti_join(county_date_pairs, 
                     protest_daily_norallies[,c("date","fips_code")]) %>% 
  mutate(protests_norallies = 0)
protest_daily_norallies <- rbind(protest_daily_norallies, missing)

# Combine protest by day data into a dataframe
protest_daily <- protest_daily_large %>% 
  inner_join(protest_daily_liberal, by = c("date", "fips_code")) %>% 
  inner_join(protest_daily_conservative, by = c("date", "fips_code")) %>%
  inner_join(protest_daily_racial, by = c("date", "fips_code")) %>%
  inner_join(protest_daily_women, by = c("date", "fips_code")) %>% 
  inner_join(protest_daily_all, by = c("date", "fips_code")) %>% 
  inner_join(protest_daily_norallies, by = c("date", "fips_code"))
```

```{r Write protest dataframes to csv}
# combine dataframes
protest_data_final <- protest_daily %>% 
  inner_join(protest_size, by = c("date", "fips_code")) 
# Write to csv
fwrite(protest_data_final, "protest_data.csv")
# remove all dataframes
rm(list=ls())
```

Following the data cleaning procedures, the final output is `protest_data.csv` (313.1MB), which contains 5 primary operationalizations of protest activity and three supplemental operationalizations of protest activity.

Primary operationalizations of protest activity (includes number of people attending the protests and count of protest events):

-   1) Sum of daily protest attendees in a county.
-   2) Sum of daily liberal protest attendees in a county (and alternative operationalization for protests that include more than 30 people and are labeled as liberal protests).
-   3) Sum of daily conservative protest attendees in a county (and alternative operationalization for protests that include more than 30 people and are labeled as conservative protests).
-   4) Sum of daily racial protest attendees in a county (and alternative operationalization for protests that include more than 30 people and are labeled as racial protests).
-   5) Sum of daily women protest attendees in a county (and alternative operationalization for protests that include more than 30 people and are labeled as women protests).

Supplemental operationalizations of protest activity:

-   1) No rallies: Sum of daily protest attendees in a county that are not "rallies" (and alternative operationalization for protests that include more than 30 people and are not labeled as rally protests).
-   2) All protests: the number of daily protest events that occur in an American county for every year from 2017 to 2022
-   3) Large protests: limits to protest events that include more than 30 people.


# FEC Campaign Contribution Data (2017-2021)

In this second section, I clean individual-level donations to federal political campaigns from the FEC website (2017-2022). All FEC data come from FEC website: https://www.fec.gov/data/browse-data/?tab=bulk-data. The cleaning procedures contain five parts: 1) cleaning the FEC candidate data and cleaning the FEC committee donation data (and joining the two together), 2) cleaning the donations made by individuals, 3) aggregating daily individual-donations by county, 4) aggregating daily individual-donations by county for temportal RDD. I describe each part in detail below.

## Part I: Clean FEC Candidate Data and FEC Committee Data

The candidate data come from the FEC website (https://www.fec.gov/campaign-finance-data/candidate-master-file-description/). For these analyses, I focus on the candidate's ID, political party, incumbency status, year, and their committee id. To better understand the partisan affiliation of each committee, I also examine committee donation data (https://www.fec.gov/campaign-finance-data/contributions-committees-candidates-file-description/). 

Final candidate dataset: `candidate_committee_full`.

```{r Function to Clean FEC Candidate Data}
clean_candidate <- function(data){
  # Data Wrangling -
  fec_candidate_subset <- data %>%
      # select subset of variables and rename
      select("CAND_ID" = V1,
             "NAME" = V2,
             "party" = V3,
             "year" = V4,
             "incumbent_status" = V8,
             "CMTE_ID" = V10) %>% 
      # Rename any party that is not Republican or Dem to "Other"
      mutate(party = case_when(party != "REP" & 
                                 party != "DEM" ~ "Other", 
                               TRUE ~ party),
             # recode incumbents
             incumbent = case_when(incumbent_status == "I" ~ 1, TRUE ~ 0),
             # recode challengers
             challenger = case_when(incumbent_status == "C" ~ 1, TRUE ~ 0)) %>%
      select(NAME, CAND_ID, CMTE_ID, party, incumbent, challenger, year) %>% 
      separate(NAME, into = c("last_name","first_name"), sep =",") %>%
      separate(first_name, into = c("middle", "first_name"), sep = " ") %>% 
      select(-middle)
  
    ### Predict candidate gender
    fec_candidate_subset <- gender(fec_candidate_subset$first_name, method = "ssa") %>% 
        mutate(female = case_when(proportion_female > 0.6 ~ 1, TRUE ~ 0)) %>% 
        mutate(unsure_gender = case_when(proportion_female > 0.49 & proportion_female < 0.61~ 1, 
                                         TRUE ~ 0)) %>% 
        distinct(name,.keep_all = TRUE) %>% 
        select(first_name = name, female,unsure_gender) %>% 
        right_join(fec_candidate_subset, by = "first_name")
    
    # ### Predict race
    # race_df <- fec_candidate_subset %>% 
    #     rename(surname = last_name) %>% 
    #     predict_race(surname.only = T) %>% 
    #     mutate(black = case_when(pred.bla > 0.6 ~ 1, TRUE ~ 0)) %>% 
    #     select(black)
    # fec_candidate_subset <- cbind(fec_candidate_subset, race_df)
  
  return(fec_candidate_subset)
}

```


```{r Candidate Data Cleaning}
# Load to get full list of counties and zip codes
zip_to_county_data <- read_excel("ZIP_COUNTY_092021.xlsx") %>% 
  select(1, 2) %>% 
  # limit to unique zip codes (bc several zip codes lie in multiple counties)
  distinct_at(vars(ZIP), .keep_all = T)

# Manually Download Candidates Data from FEC website and read in .txt file (https://www.fec.gov/data/browse-data/?tab=bulk-data)
# Candidate Master
# 2017-2018: https://www.fec.gov/files/bulk-downloads/2018/cn18.zip
candidate_2018 <- fread("candidate_18.txt", 
                        sep = "|", header = FALSE, stringsAsFactors = FALSE)
candidate_2018 <- clean_candidate(candidate_2018)
# 2019-2020: https://www.fec.gov/files/bulk-downloads/2020/cn20.zip
candidate_2020 <- fread("candidate_20.txt", 
                        sep = "|", header = FALSE, stringsAsFactors = FALSE)
candidate_2020 <- clean_candidate(candidate_2020)
# 2021-2022: https://www.fec.gov/files/bulk-downloads/2022/cn22.zip
candidate_2022 <- fread("candidate_22.txt", 
                        sep = "|", header = FALSE, stringsAsFactors = FALSE)
candidate_2022 <- clean_candidate(candidate_2022)
# Combine the fec candidate data
candidate_fec <- rbind(candidate_2018, candidate_2020, candidate_2022)

candidate_fec <- candidate_fec %>% 
  filter(year == 2017 | year == 2018 | year == 2019 | year == 2020 | year == 2021 | year == 2022)

# Examine missing committee IDs 
# 3402 out of 18531 candidates do not have committee ids (18.4 percent missing)
print(nrow(candidate_fec[candidate_fec$CMTE_ID == "",])/nrow(candidate_fec))

fwrite(candidate_fec, "candidate_fec.csv")

rm(list=ls())

```

```{r}
# write function to clean committee data
committee_wrangling <- function(committee_data, candidate_data){
  
  data_new <- committee_data %>% 
    select(CMTE_ID, TRANSACTION_DT, CAND_ID) %>% 
    mutate(TRANSACTION_DT = as.character(TRANSACTION_DT),
            # create year variable
            year = as.numeric(str_sub(TRANSACTION_DT, -4, -1))) %>% 
    # join data to candidate data
    left_join(candidate_data, by = c("CAND_ID","year")) %>% 
    # aggregate all donations by committee id and year
    group_by(CMTE_ID, year) %>% 
    # combine which party each committee donated to
    summarize(party_total = paste(party, collapse = " | ")) %>% 
    mutate(party_total = case_when(is.na(party_total) ~ "Other",
                                   TRUE ~ party_total)) %>% 
    # separate the donations into new rows to calculate donation distribution
    separate_rows(party_total, sep = " \\| ") %>% 
    mutate(party_total = case_when(party_total == "NA" ~ "Other",
                                   TRUE ~ party_total)) %>% 
    group_by(CMTE_ID, party_total, year) %>% 
    # count how many times a committee donated to a party
    count() %>% 
    pivot_wider(names_from = party_total, values_from = n) %>% 
    # convert the donation stats into percentages
    summarize(dem_percent = DEM /(DEM + REP),
              rep_percent = REP /(DEM + REP)) %>% 
    # If a party donated to one of the parties more than 60% of the time, classify the committee as more favorable to that party
    mutate(party = case_when(is.na(dem_percent) ~ "Other", 
                             dem_percent > 0.59 ~ "DEM",
                             rep_percent > 0.59 ~ "REP",
                             TRUE ~ "Other")) %>% 
    select(CMTE_ID, party, year) %>% 
    mutate(incumbent = NA, challenger = NA, female = NA, unsure_gender = NA) %>% 
    ungroup()
  
  return(data_new)
}

# Helper function for calculating mode
getmode <- function(v) {
  uniqv <- unique(v)
  uniqv[which.max(tabulate(match(v, uniqv)))]
}

```


```{r}
##### Clean committee data

# read in candidate_fec
candidate_fec <- read_csv("candidate_fec.csv") 
candidate_fec_sub <- candidate_fec %>% 
  select(CAND_ID, year, party)

# committee header
committee_header <- read_csv("committee_header_file.csv")

# Committee data
#2018
committee_2018 <- fread("committee_2018.txt", 
                        sep = "|", header = FALSE, stringsAsFactors = FALSE)
colnames(committee_2018) <- colnames(committee_header)
committee_2018<- committee_wrangling(committee_2018, candidate_fec_sub)
#2020
committee_2020 <- fread("committee_2020.txt", 
                        sep = "|", header = FALSE, stringsAsFactors = FALSE)
colnames(committee_2020) <- colnames(committee_header)
committee_2020<- committee_wrangling(committee_2020, candidate_fec_sub)
#2022
committee_2022 <- fread("committee_2022.txt", 
                        sep = "|", header = FALSE, stringsAsFactors = FALSE)
colnames(committee_2022) <- colnames(committee_header)
committee_2022<- committee_wrangling(committee_2022, candidate_fec_sub)

# combine together with candidate data
candidate_fec <- candidate_fec %>% 
  select(-CAND_ID, -first_name, -last_name)
candidate_committee_full <- rbind(candidate_fec, committee_2018, 
                                  committee_2020, committee_2022)

candidate_committee_full <- candidate_committee_full %>% 
  filter(!is.na(CMTE_ID)) %>% 
  distinct(CMTE_ID, year, .keep_all = T) 
  
fwrite(candidate_committee_full, "candidate_committee_full.csv")

rm(list=ls())
```

## Part II: Clean Individual-level FEC Contribution data

In part II, I clean the FEC individual contribution data. The raw data comes from https://www.fec.gov/data/browse-data/?tab=bulk-data, under the section "Contribution by individuals." Please note that manually downloading the data and running this section of the code is very slow, because it is cleaning large files. Expect the download process to take around 4-5 hours and the cleaning process to take around 2-4 hours. 

```{r Create Function for Data Wrangling - FEC Contribution Data}

# Create function to clean the FEC data
fec_cleaning <- function(file) {
  
  # Read in data from FEC website
  data <- fread(file,
                sep = "|", header = FALSE,
                stringsAsFactors = FALSE)

  # Rename columns
  colnames(data) <- colnames(header)
  
  data_cleaned <- data %>% 
      select(NAME, STATE, CITY, ZIP_CODE, CMTE_ID, 
           TRANSACTION_DT, TRANSACTION_AMT) %>% 
      mutate(TRANSACTION_DT = as.character(TRANSACTION_DT),
            # create year variable
            year = as.numeric(str_sub(TRANSACTION_DT, -4, -1)),
            # keep first 5 characters of zip code
            ZIP_CODE = substr(ZIP_CODE, 1, 5),
            # if data is only 7 characters, add 0 in front (loading in drops leading zero)
            TRANSACTION_DT = case_when(
              nchar(TRANSACTION_DT) == 7 ~ paste0("0", TRANSACTION_DT),
              TRUE ~ TRANSACTION_DT),
            # cast data to date type variable
            TRANSACTION_DT = as.Date(
              str_replace(TRANSACTION_DT, 
                          "(\\d{2})(\\d{2})(\\d{4})$", 
                          "\\1-\\2-\\3"),
              format = "%m-%d-%Y")) %>% 
      filter(year == "2017" | year == "2018" | 
               year == "2019" | year == "2020" | year == "2021" | year == "2022") %>% 
      left_join(zip_to_county_data, by = c("ZIP_CODE" = "ZIP")) %>% 
      left_join(candidate_committee_full, by = c("CMTE_ID", "year")) %>% 
      mutate(dem = case_when(party == "DEM" ~ 1,
                             TRUE ~ 0),
             rep = case_when(party == "REP" ~ 1,
                             TRUE ~ 0)) 
    
  # print status report
  print(paste("Complete", file))
  print(Sys.time())
  
  return(data_cleaned)
}

```

```{r Data Wrangling - FEC Contribution Data}
##### This cell cleans all the FEC individual-level donations from the FEC website
### Please note, this cell will take about 2-5 hours to run

# Contribution data
# Source: https://www.fec.gov/campaign-finance-data/contributions-individuals-file-description/
start.time <- Sys.time()

# read in candidate data
candidate_committee_full <- fread("candidate_committee_full.csv")
# Load to get full list of counties and zip codes
zip_to_county_data <- read_excel("ZIP_COUNTY_092021.xlsx") %>% 
  select(1, 2) %>% 
  # limit to unique zip codes (bc several zip codes lie in multiple counties)
  distinct_at(vars(ZIP), .keep_all = T)

# Read in FEC contribution header
header <- fread("indiv_header_file.csv")

# Write function to preprocess the data
fec_process <- function(){
  # 2017-2018 FEC individual contributions
  # Source: https://www.fec.gov/files/bulk-downloads/2018/indiv18.zip
  file <- "fec_2018.txt"
  fec_cleaned_2017_2018 <- fec_cleaning(file)
  fwrite(fec_cleaned_2017_2018, "fec_cleaned_2017_2018.csv")
  
  # 2019-2020 FEC individual contributions
  # Source: https://www.fec.gov/files/bulk-downloads/2020/indiv20.zip
  file <- "fec_2020.txt"
  fec_cleaned_2019_2020 <- fec_cleaning(file)
  fwrite(fec_cleaned_2019_2020, "fec_cleaned_2019_2020.csv")
  
  # 2021-2022 FEC individual contributions
  # Source: https://www.fec.gov/files/bulk-downloads/2022/indiv22.zip
  file <- "fec_2022.txt"
  fec_cleaned_2021_2022 <- fec_cleaning(file)
  fwrite(fec_cleaned_2021_2022, "fec_cleaned_2021_2022.csv")
  
  # Bind FEC donation data by row
  fec_cleaned <- rbind(fec_cleaned_2017_2018,
                       fec_cleaned_2019_2020,
                       fec_cleaned_2021_2022)
  
  return(fec_cleaned)
}

# Process data
fec_cleaned <- fec_process()
# write to csv
fwrite(fec_cleaned, "fec_cleaned.csv")
end.time <- Sys.time()

```

```{r}
# # write function to add gender in for all respondents

# fec_cleaned <- fec_cleaned %>% 
#       separate(NAME, into = c("last_name","first_name"), sep =",") %>%
#       separate(first_name, into = c("middle", "first_name"), sep = " ") %>%
#       select(-middle)
# 
# ### Predict gender
# fec_cleaned <- gender(fec_cleaned$first_name) %>%
#     mutate(female_donor = case_when(proportion_female > 0.6 ~ 1, TRUE ~ 0)) %>%
#     mutate(unsure_gender = case_when(proportion_female > 0.49 & proportion_female < 0.61~ 1, 
#                                          TRUE ~ 0)) %>%
#     distinct(name,.keep_all = TRUE) %>%
#     select(first_name = name, female_donor) %>%
#     right_join(fec_cleaned, by = "first_name")
  
```

```{r}

# add final variables

fec_cleaned <- fec_cleaned %>% 
        mutate(other_party = case_when(party == "Other" ~ 1,
                             TRUE ~ 0),
               no_party = case_when(is.na(party) | party == "" ~ 1,
                             TRUE ~ 0),
               no_gender = case_when(is.na(female) ~ 1,
                             TRUE ~ 0)) %>% 
         replace_na(list(female=0))

fwrite(fec_cleaned, "fec_cleaned.csv")
```


The shape of the resulting data frame (i.e., `fec_cleaned`) is 158,872,613 rows (13.5 GB). The data includes individual-level FEC contributions for the years 2017-2022. The data includes the time of the donation (i.e., date), the donation location (i.e., zip code and county), the donation amount, committee id, partisanship of candidate/committee receiving the donation, and (predicted) gender of candidate receiving the donation.

```{r}
##### Descriptive statistics about FEC individual-level data

options(scipen = 0, digits = 12) 

# Total contribution amount?
sum(fec_cleaned[fec_cleaned$TRANSACTION_AMT < 3001 & fec_cleaned$TRANSACTION_AMT > 0, "TRANSACTION_AMT"])
# 15,531,700,409

# how many contributions are given to democrats? republicans?
# how many cannot be located?
fec_cleaned %>% 
  group_by(party) %>% 
  count()
# Dem: 13.2 % (16.9% of all parties)
# Rep: 7.8 % (10 % of all parties)
# Other (including mixed donations): 56.9 %
# NA: 22%

# donations by gender
fec_cleaned %>% 
  group_by(female) %>% 
  count()
# female: 3.5 %
# not female: 8.9 %
# unsure: of all the candidates, only 0.039% of donations were made to unsure names
# NA: 87.6 %

#^^^ this means only 12.3% of donations were made to candidates.....

```


## Part III: Aggregate Daily Individual-level FEC Data by County

In part III, I aggregate the daily number/amount of donations in a county. I complete this aggregation for four groupings: all donations, donations made to Democrats, donations made to Republicans, and donations made to women.

```{r Read in FEC Data}
# If previously downloaded FEC data, read into R
fec_cleaned <- fread("fec_cleaned.csv")
```

```{r Helper Functions - Aggregate FEC Data -- weekly and daily}

# Summarize FEC donations BY NUMBER of donations per day and county
summarize_fec_count <- function(data){
  # data: cleaned FEC data

  out <- data %>% 
          # group by county, date, year, and all other grouping vars
          group_by(COUNTY, TRANSACTION_DT, year, dem, rep, female,
                   other_party, no_party, no_gender) %>%
          # count the number of donations per day per county
          summarize(number_donations = n()) %>%
          ungroup() %>%
          # create every combination of day and fips county
          tidyr::complete(TRANSACTION_DT, COUNTY) %>%
          # fill NA values with 0 (since not every county has donations in a given time... the NAs come from complete())
          replace_na(list(number_donations=0)) %>% 
          drop_na() %>% 
          rename(fips_code = COUNTY, date = TRANSACTION_DT) %>% 
          mutate(week_data = 0, date = as.Date(date))
  return(out)
}

# Summarize FEC donations BY AMOUNT of donation per day and county
summarize_fec_amount <- function(data){
  
  # separate weekly cleaning from daily cleaning
   out <- data %>% 
        # Filter for donations under the individual limit and over 0
        filter(TRANSACTION_AMT < 3001 & TRANSACTION_AMT > 0) %>% 
        # group by county, date, year, and all other grouping vars
        group_by(COUNTY, TRANSACTION_DT, year, dem, rep, female,
                 other_party, no_party, no_gender) %>%
        # sum the amount of donations per day per county
        summarize(amount_donations = sum(TRANSACTION_AMT)) %>%
        ungroup() %>%
        # create every combination of day and fips county
        tidyr::complete(TRANSACTION_DT, COUNTY) %>%
        # fill NA values with 0 (since not every county has donations in a given time... the NAs come from complete())
        replace_na(list(amount_donations=0)) %>% 
        drop_na() %>% 
        rename(fips_code = COUNTY, date = TRANSACTION_DT) %>% 
        mutate(week_data = 0, date = as.Date(date))

  return(out)
}

combine_amount_count <- function(fec_data, day){
  fec_count <- summarize_fec_count(fec_data)
  fec_amount <- summarize_fec_amount(fec_data)

  fec_out <- fec_count %>% 
          full_join(fec_amount, by = c("date", "week_data","fips_code",
                                       "year","dem","rep", 
                                       "female","other_party",
                                       "no_party","no_gender")) %>% 
          replace(is.na(.), 0)
  
  # Find missing date-county pair
  missing <- anti_join(county_date_pairs, 
                       fec_out[,c("date","fips_code", "week_data", "year")])
  fec_out <- rbind(fec_out, missing)
  
  return(fec_out)
}



### Dealing with missing values
# Since not every date has a donation in every county, not every date-county pair populates. 

# Load to get full list of counties and zip codes
zip_to_county_data <- read_excel("ZIP_COUNTY_092021.xlsx") %>%
  select(1, 2) %>%
  # limit to unique zip codes (bc several zip codes lie in multiple counties)
  distinct_at(vars(ZIP), .keep_all = T)
# Manually add in missing date-county pairs
full_dates <- seq.Date(as.IDate("2017-01-01"), as.IDate("2022-12-31"), by="days")
full_counties <- unique(zip_to_county_data$COUNTY)
county_date_pairs <- expand.grid(full_dates, full_counties) %>%
  rename(date = Var1, fips_code = Var2) %>%
  mutate(TRANSACTION_DT = as.character(date),
        # create year variable
        year = as.numeric(str_sub(TRANSACTION_DT, 1, 4)),
        week_data = 0, fips_code = as.character(fips_code),
        dem = 0, rep = 0, female = 0, other_party = 0, no_party = 1,
        no_gender = 1, number_donations = 0, amount_donations = 0) %>% 
  select(-TRANSACTION_DT)
  
```

```{r}
# If previously downloaded FEC data, read into R
fec_daily <- fread("fec_daily.csv")

```



```{r}
# roughly 30 min to run
print(Sys.time())

# 1) Number/amount of daily donations per county 
fec_daily <- combine_amount_count(fec_cleaned, TRUE)
fec_daily <- fec_daily %>% 
  mutate(fips_code = as.integer(as.character((fips_code))),
         date = as.character(date))

# join to protest data
protest_data_full <- fread("protest_data.csv")
protest <- protest_data_full %>% 
  mutate(TRANSACTION_DT = as.character(date),
        # create year variable
        year = as.numeric(str_sub(TRANSACTION_DT, 1, 4))) %>% 
  select(-TRANSACTION_DT) 

fec_daily <- fec_daily %>% 
  left_join(protest, by = c("date","fips_code","year"))


fwrite(fec_daily, "fec_daily.csv")
print(Sys.time())
```



## Part IV: Aggregate Individual-level FEC Data BY DAY (2017/2018 only; for temporal RDD analysis)

In part V, I aggregate the FEC individual-level donations by day across the whole country for end of 2017 through early 2018 only. This data is used for an RDD that uses the school shootings in Parkland, FL as an exogenous shock that increased protests across the country. As a result, I examine donations before and after the March for our Lives protests on March 24th, 2018. Final dataset is `fec_march_daily_full`.

```{r Function to aggregate FEC donations by day for various groupings}

# Aggregate Donations Per Day By Group
fec_march_wrangling <- function(data) {
  
  ##### Aggregate donation data by day and create day variable indicating time around march for our lives
  
  # Number of daily donations
  fec_march_count_all <- data %>%
    # filter for just 2017/2018
    filter(year == 2017 |year == 2018) %>%
    mutate(data = as.Date(date),
           # create indicator for march for our lives
           march = as.Date("03-24-2018", format = "%m-%d-%Y"),
           # Get distance from march
           days = difftime(date, march, units = "days"),
           # Create indicator if after march
           after = as.factor(case_when(days > 0 ~ 1, TRUE ~ 0))) %>%
    arrange(days) 
  
  # Do same thing as above but create separate table for transaction amounts rather than count
  fec_march_amount_all <- data %>%
    # filter for just 2017/2018
    filter(year == 2017 | year == 2018) %>% 
    mutate(data = as.Date(date),
          # create indicator for march for our lives
          march = as.Date("03-24-2018", format = "%m-%d-%Y"),
          # Get distance from march
          days = difftime(date, march, units = "days"),
          # Create indicator if after march
          after = as.factor(case_when(days > 0 ~ 1, TRUE ~ 0))) %>%
    arrange(days)
  
    ######### Primary Datasets
  ##### 1) group total - number of donations by day
  fec_total_count <- fec_march_count_all %>%
    group_by(fips_code, date, days, after, dem, rep,
             other_party, no_party) %>%
    summarize(number_donations = sum(number_donations))
  
  ##### 2) group total - amount of donations by day
  fec_total_amount <- fec_march_amount_all %>%
    group_by(fips_code,date, days, after, dem, rep,
             other_party, no_party) %>%
    summarize(amount_donations = sum(amount_donations))
  
  # combine all the grouped data into a single dataset
  fec_march_daily_full <- fec_total_count %>% 
    inner_join(fec_total_amount, by = c("fips_code", "date","days", "after", "dem", "rep",
                                        "other_party", "no_party"))
    
  return(fec_march_daily_full)
}
```



```{r}
# Note: this code block takes around 15 minutes to run
#fec_daily <- fread("fec_daily.csv")
print(Sys.time())
fec_march_daily_full <- fec_march_wrangling(fec_daily)
fec_march_daily_full <- fec_march_daily_full %>% 
  mutate(days = floor(as.numeric(days))) %>% 
  filter(days > -121 & days < 121) %>% 
  select(-date.y) %>% 
  rename(date = date.x)

fwrite(fec_march_daily_full, "fec_march_daily_full.csv")
print(Sys.time())

```

